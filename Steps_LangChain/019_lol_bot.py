from langchain.prompts import ChatPromptTemplate
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

url = "https://namu.wiki/w/ë¦¬ê·¸ ì˜¤ë¸Œ ë ˆì „ë“œ/ì±”í”¼ì–¸/ì—­í• êµ°"
loader = WebBaseLoader(
    web_paths=(url,),
)
docs = loader.load()
# print(docs)

text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
splits = text_splitter.split_documents(docs)
# print(splits)

embeddings = OpenAIEmbeddings()
vector_store = Chroma.from_documents(
    documents=splits,
    embedding=embeddings,
    persist_directory="my_vector_store",
)

retriever = vector_store.as_retriever()


prompt = ChatPromptTemplate.from_template(
    """
ë‹¹ì‹ ì€ ë¦¬ê·¸ ì˜¤ë¸Œ ë ˆì „ë“œ ì±”í”¼ì–¸ ì—­í• êµ°ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë´‡ì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”.
ë‹µë³€ì€ ìµœëŒ€ ì„¸ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

Question: {question}
Context: {context}
Answer: """
)

question = input("ğŸ¦Š ì§ˆë¬¸: ")
print(f"ğŸ¦Š ì§ˆë¬¸: {question}")

docs = retriever.invoke(question)
context = "\n".join([doc.page_content for doc in docs])

llm = ChatOpenAI(model="gpt-4o-mini")

chain = prompt | llm
res = chain.invoke({"context": context, "question": question})
print(f"ğŸ¤– ë‹µë³€: {res.content}")
