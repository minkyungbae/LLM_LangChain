import pyfiglet
from langchain.prompts import ChatPromptTemplate
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ê¸°ì¡´ ì„ë² ë”©ëœ ë°ì´í„° í™œìš©
embeddings = OpenAIEmbeddings()
vector_store = Chroma(
    persist_directory="my_vector_store", embedding_function=embeddings
)

# ë²¡í„° DBê°€ ë¹„ì–´ ìˆëŠ”ì§€ ì²´í¬
if not vector_store._collection.count():
    print("âš ï¸ ê¸°ì¡´ ë²¡í„° DBì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì„ë² ë”©ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
else:
    print("âœ… ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

print(pyfiglet.figlet_format("Sparta LoL Bot"))

retriever = vector_store.as_retriever()

prompt = ChatPromptTemplate.from_template(
    """
ë‹¹ì‹ ì€ ë¦¬ê·¸ ì˜¤ë¸Œ ë ˆì „ë“œ ì±”í”¼ì–¸ ì—­í• êµ°ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë´‡ì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”.
ë‹µë³€ì€ ìµœëŒ€ ì„¸ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

Question: {question}
Context: {context}
Answer: """
)

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
question = input("ğŸ¦Š ì§ˆë¬¸: ")

# ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
docs = retriever.invoke(question)
context = "\n".join([doc.page_content for doc in docs])

# LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini")

# RAG ì‹¤í–‰
chain = prompt | llm
res = chain.invoke({"context": context, "question": question})

print(f"ğŸ¤– ë‹µë³€: {res.content}")
